{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f87d87a-882d-4ebc-9dba-0818596d82ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: pinecone-client==2.2.4 in ./.local/lib/python3.9/site-packages (2.2.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/site-packages (from pinecone-client==2.2.4) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.9/site-packages (from pinecone-client==2.2.4) (6.0)\n",
      "Requirement already satisfied: loguru>=0.5.0 in ./.local/lib/python3.9/site-packages (from pinecone-client==2.2.4) (0.7.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in ./.local/lib/python3.9/site-packages (from pinecone-client==2.2.4) (4.8.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in ./.local/lib/python3.9/site-packages (from pinecone-client==2.2.4) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.9/site-packages (from pinecone-client==2.2.4) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.9/site-packages (from pinecone-client==2.2.4) (1.26.6)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in ./.local/lib/python3.9/site-packages (from pinecone-client==2.2.4) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./.local/lib/python3.9/site-packages (from pinecone-client==2.2.4) (1.26.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.5.3->pinecone-client==2.2.4) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.19.0->pinecone-client==2.2.4) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests>=2.19.0->pinecone-client==2.2.4) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests>=2.19.0->pinecone-client==2.2.4) (2023.7.22)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in ./.local/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in ./.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (4.31.0)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in ./.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (2.0.1)\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (0.15.2)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (1.26.1)\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (1.3.2)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (1.11.3)\n",
      "Requirement already satisfied: nltk in ./.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in ./.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (0.18.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.12.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.1)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers==2.2.2) (58.1.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers==2.2.2) (0.41.2)\n",
      "Requirement already satisfied: cmake in ./.local/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers==2.2.2) (3.27.7)\n",
      "Requirement already satisfied: lit in ./.local/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers==2.2.2) (17.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.0)\n",
      "Requirement already satisfied: click in ./.local/lib/python3.9/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.local/lib/python3.9/site-packages (from nltk->sentence-transformers==2.2.2) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.9/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/site-packages (from torchvision->sentence-transformers==2.2.2) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.local/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: torch==2.0.1 in ./.local/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (1.12)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1) (3.1.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (58.1.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.41.2)\n",
      "Requirement already satisfied: cmake in ./.local/lib/python3.9/site-packages (from triton==2.0.0->torch==2.0.1) (3.27.7)\n",
      "Requirement already satisfied: lit in ./.local/lib/python3.9/site-packages (from triton==2.0.0->torch==2.0.1) (17.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->torch==2.0.1) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.local/lib/python3.9/site-packages (from sympy->torch==2.0.1) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "## Install dependencies\n",
    "!pip install pinecone-client==2.2.4\n",
    "!pip install sentence-transformers==2.2.2\n",
    "!pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a27c0327-3e10-47f9-a063-62ffaaeb8527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Import dependencies\n",
    "import os\n",
    "import pinecone\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "246346f4-47e3-448b-a49d-7295b568de97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Initialize environment variables (change api key and environment to be your own)\n",
    "PINECONE_API_KEY= \"insert yours here\"\n",
    "PINECONE_ENV = \"gcp-starter\"\n",
    "PINECONE_INDEX = \"cml-default\"\n",
    "EMBEDDING_MODEL_REPO = \"sentence-transformers/all-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4c2f849-3a82-4d6e-8aaa-315ddb5c17e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "indexes = pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6736b62-8d87-4351-aef9-cbdc49d9cc80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexDescription(name='cml-default', metric='cosine', replicas=1, dimension=768.0, shards=1, pods=1, pod_type='starter', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')\n",
      "Successfully loaded cml-default\n"
     ]
    }
   ],
   "source": [
    "if PINECONE_INDEX not in indexes:\n",
    "    pinecone.create_index(PINECONE_INDEX, dimension=768, metric=\"euclidean\")\n",
    "    \n",
    "index_description = pinecone.describe_index(PINECONE_INDEX)\n",
    "print(index_description)\n",
    "\n",
    "collection = pinecone.Index(PINECONE_INDEX)\n",
    "print(\"Successfully loaded \" + PINECONE_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10ac6e6f-d189-4df6-93b6-17a0ab933320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the model stored in models/embedding-model\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_REPO)\n",
    "model = AutoModel.from_pretrained(EMBEDDING_MODEL_REPO)\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Create embeddings using chosen embedding-model\n",
    "def get_embeddings(sentence):\n",
    "    # Sentences we want sentence embeddings for\n",
    "    sentences = [sentence]\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    # Default model will truncate the document and only gets embeddings of the first 256 tokens.\n",
    "    # Semantic search will only be effective on these first 256 tokens.\n",
    "    # Context loading will still include the ENTIRE document file\n",
    "    encoded_input = tokenizer(sentences, padding='max_length', truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    return (sentence_embeddings.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa068a92-1c7a-4121-b180-eb7c7053312c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for: ml-product-overview-2.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: ml-product-overview-4.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: ml-product-overview.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: ml-product-overview-3.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: ml-product-overview-5.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: ml-architecture-overview-spark-on-kubernetes.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: ml-architecture-overview1.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: ml-architecture-overview-cml-1.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: ml-architecture-overview-cml-2.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: ml-architecture-overview-runtimes.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: ml-architecture-overview-provisioning.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: iceberg-snippet.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: iceberg-snippet-checkpoint.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Generating embeddings for: ozone-snippet.txt\n",
      "Upserting vectors...\n",
      "Success\n",
      "Finished loading Knowledge Base embeddings into Pinecone\n"
     ]
    }
   ],
   "source": [
    "## Use documents in /data directory and insert embeddings into Vector DB for each doc\n",
    "def insert_embedding(pinecone_index, id_path, text):\n",
    "    print(\"Upserting vectors...\")\n",
    "    vectors = list(zip([text[:512]], [get_embeddings(text)], [{\"file_path\": id_path}]))\n",
    "    upsert_response = pinecone_index.upsert(\n",
    "        vectors=vectors\n",
    "        )\n",
    "    print(\"Success\")\n",
    "\n",
    "# Create an embedding for given text/doc and insert it into Pinecone Vector DB\n",
    "doc_dir = './data'\n",
    "for file in Path(doc_dir).glob(f'**/*.txt'):\n",
    "    with open(file, \"r\") as f: # Open file in read mode\n",
    "        print(\"Generating embeddings for: %s\" % file.name)\n",
    "        text = f.read()\n",
    "        insert_embedding(collection, os.path.abspath(file), text)\n",
    "print('Finished loading Knowledge Base embeddings into Pinecone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50f5361a-6228-4d25-84b0-47f17808f58a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Setup function to convert user question into an embedding returning most relevant response (semantic search)\n",
    "def get_response_from_pinecone_vectordb(index, question):\n",
    "    # Generate embedding for user question with embedding model\n",
    "    retriever = SentenceTransformer(EMBEDDING_MODEL_REPO)\n",
    "    xq = retriever.encode([question]).tolist()\n",
    "    xc = index.query(xq, top_k=5,\n",
    "                 include_metadata=True)\n",
    "    \n",
    "    matching_files = []\n",
    "    scores = []\n",
    "    for match in xc['matches']:\n",
    "        # extract the 'file_path' within 'metadata'\n",
    "        file_path = match['metadata']['file_path']\n",
    "        # extract the individual scores for each vector\n",
    "        score = match['score']\n",
    "        scores.append(score)\n",
    "        matching_files.append(file_path)\n",
    "\n",
    "    # Return text of the nearest knowledge base chunk \n",
    "    # Note that this ONLY uses the first matching document for semantic search. matching_files holds the top results so you can increase this if desired.\n",
    "    response = load_context_chunk_from_data(matching_files[0])\n",
    "    sources = matching_files[0]\n",
    "    score = scores[0]\n",
    "    return response, sources, score\n",
    "  \n",
    "# Return the Knowledge Base doc based on Knowledge Base ID (relative file path)\n",
    "def load_context_chunk_from_data(id_path):\n",
    "    with open(id_path, \"r\") as f: # Open file in read mode\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8d5f469-93af-49f5-b2b7-7d7f008272d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Path: /home/cdsw/data/iceberg/iceberg-snippet.txt\n",
      "Pinecone relevancy score: 0.393630356\n",
      "Apache Iceberg is an open table format for huge analytic datasets. Iceberg adds tables to compute engines including Spark, Trino, PrestoDB, Flink, Hive and Impala using a high-performance table format that works just like a SQL table.\n",
      "\n",
      "User experience\n",
      "Iceberg avoids unpleasant surprises. Schema evolution works and won't inadvertently un-delete data. Users don't need to know about partitioning to get fast queries.\n",
      "\n",
      "Schema evolution supports add, drop, update, or rename, and has no side-effects\n",
      "Hidden partitioning prevents user mistakes that cause silently incorrect results or extremely slow queries\n",
      "Partition layout evolution can update the layout of a table as data volume or query patterns change\n",
      "Time travel enables reproducible queries that use exactly the same table snapshot, or lets users easily examine changes\n",
      "Version rollback allows users to quickly correct problems by resetting tables to a good state\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Write a query and trigger a semantic search (show document, location, and score)\n",
    "## Note that if you're running this script for the first time, you may have to run this block twice\n",
    "USER_QUESTION = \"What is Iceberg\" ## (replace this with your own from content in your knowledge base)\n",
    "response, source, score = get_response_from_pinecone_vectordb(collection, USER_QUESTION)\n",
    "print(\"Source Path: \" + source)\n",
    "print(\"Pinecone relevancy score: \" + str(score))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
